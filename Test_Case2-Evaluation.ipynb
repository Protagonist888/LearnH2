{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20cc6a13",
   "metadata": {},
   "source": [
    "# LangChain: Evaluation¶\n",
    "### Outline:\n",
    "* Example generation\n",
    "* Manual evaluation (and debuging)\n",
    "* LLM-assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12b2ded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key:········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "import openai\n",
    "import time\n",
    "import markdown\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358f8c3",
   "metadata": {},
   "source": [
    "# Create our QandA application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3a4beefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "#PDF directory loader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "769cc14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = 'GlobalPowerPlantDB_USonly.csv'\n",
    "pdf_folder_path = \"/Users/markc/Hydrogen/\"\n",
    "loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73c0ee9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=' Global Hydrogen Review 2022   \\nPAGE | 42  Hydrogen  demand  \\n \\nStock of fuel cell electric vehicles exceeded 50 000 in 2021 \\nFuel cell electric vehicle stock by segment and region, 2017- June 2022  \\n \\nIEA. All rights reserved.  \\nNote: US = United States; RoW = rest of world.  \\nSources: Advanced Fuel Cells Technology Collabor ation Programme ; California Fuel Cell Partnership ; International Partnership for Hydrogen and Fuel Cells in the Economy ; US \\nDepartment of Energy Hydrogen and Fuel Cell Technologies Office; Korea’s Ministry of Trade, Industry and Energy monthly automobile updates ; Clean Energy Ministerial Hydrogen \\nInitiative country surveys. 10203040506070\\n2017 2018 2019 2020 2021 Jun-22Fuel cell electric vehicles \\n(thousand)\\nTotal Cars Buses Commercial vehicles2017 2018 2019 2020 2021 Jun-22\\nKorea US China Japan Europe RoW', metadata={'source': '\\\\Users\\\\markc\\\\Hydrogen\\\\GlobalHydrogenReview2022_IEA.pdf', 'page': 41})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fbfd9abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficient vectorstor method?\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "02d00bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why does chain_type not accept map_reduce?\n",
    "llm = ChatOpenAI(temperature = 0.0)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=index.vectorstore.as_retriever(), \n",
    "    verbose=True,\n",
    "    chain_type_kwargs = {\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f22e2",
   "metadata": {},
   "source": [
    "# Coming up with test datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6230250a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=' \\n31  \\nThis report is available at no cost from the National Renewable Energy Laboratory at www.nrel.gov/publications . Hydrogen Production Potential Summary  \\nTable 5 summarizes energy inputs required to produce 1 kilogr am of hydrogen from each \\nresource. Conversion pathways and production efficiencies, on an LHV basis, are shown for each \\nresource . The required coal value has been updated from the 2013 Resource Report to be \\nconsistent with the NETL (2010) state- of-the- art coal case (2.2 case study) production process \\nenergy efficiency . Key conversion factors are indicated in  Table 6. We assume wind, solar , water \\npower, and geothermal resources produce hydrogen at a rate of 51.3 kWh/kg hydrogen via central electrolysis (see H2A case study).  \\nHydrogen production potential estimates for the nuclear pathway include updated assumptions about uranium use that are not included in the most recent H2A case studies. Fo r HTE , we \\nassume a nominal burnup rate of 60 GW dt/tonne U , as well as an  estimate that a 600  MW t plant \\ncan produce 85×10\\n6 scf/day of hydrogen, and therefore has  a conversion efficiency of 50.2 % for \\nheat to hydrogen (LHV) (O’Brien  2017). These assumptions result in a nominal use rate of \\n4.62×10-5 kg U/ kg hydrogen. This value is used to determine uranium resource requirements for \\nthe HTE  production pathway. Both the nominal burnup rate and the daily hydrogen production \\nfor a 600 MWt plant have been updated since the 2013 Resource Report, resulting in a higher conversion efficiency and lower uranium- to-hydrogen use rates. The nuclear  production \\nefficiency  described above is detailed further in Appendix A. ', metadata={'source': '\\\\Users\\\\markc\\\\Hydrogen\\\\Conelly_HydrogenResource.pdf', 'page': 41})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "38eecccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1771"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8661bc8a",
   "metadata": {},
   "source": [
    "# LLM-Generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1ec7977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four boxes below generate Q&A pair to evaluate model\n",
    "from langchain.evaluation.qa import QAGenerateChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18545eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in OpenIA language model to interact with chain\n",
    "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37eb538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get back dictionary of question/answer pairs to evaluate\n",
    "#\n",
    "new_examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t} for t in data[:10]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3416dfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is Exhibit 3-19 in the document about?',\n",
       " 'answer': 'Exhibit 3-19 in the document is about the MDEA CO2 capture process typical flow diagram for reforming plants.'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_examples[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "69b17e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "examples += new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3b51a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The context provided does not include any information about Exhibit 3-19.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(examples[9][\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289ecafa",
   "metadata": {},
   "source": [
    "# Manual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "40993c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "638d5879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What is the purpose of section 2.7 in the document?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain > 3:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is the purpose of section 2.7 in the document?\",\n",
      "  \"context\": \"demonstrations are discussed in Section 6. Section 7 discusses areas of consensus, disagreement, and uncertainty in \\nthe present literature and summarizes remaining research questions. \\n6 \\nThis report is available at no cost from the National Renewable Energy Laboratory (NREL) at www.nrel.gov/publications<<<<>>>>>This page intentionally left blank<<<<>>>>>the standard is to provide a reasonable level of safety, property preservation, and publ ic \\nwelfare from the hazards created by fire, explosion  and hazardous conditions associated with \\ngaseous and liquified hydrogen.  \\n3. Short Summary of the Topic of the Standard  \\nThis standard addresses the items in item #2 in detail. It covers a variety of items including \\nfire prevention control area, occupancy, piping systems (grounding, \\nconstruction/materials/pressure relief), ventilation, electrical equipment, fire alarms,<<<<>>>>>conclusions of the report.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain > 3:chain:LLMChain > 4:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Use the following pieces of context to answer the users question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\ndemonstrations are discussed in Section 6. Section 7 discusses areas of consensus, disagreement, and uncertainty in \\nthe present literature and summarizes remaining research questions. \\n6 \\nThis report is available at no cost from the National Renewable Energy Laboratory (NREL) at www.nrel.gov/publications<<<<>>>>>This page intentionally left blank<<<<>>>>>the standard is to provide a reasonable level of safety, property preservation, and publ ic \\nwelfare from the hazards created by fire, explosion  and hazardous conditions associated with \\ngaseous and liquified hydrogen.  \\n3. Short Summary of the Topic of the Standard  \\nThis standard addresses the items in item #2 in detail. It covers a variety of items including \\nfire prevention control area, occupancy, piping systems (grounding, \\nconstruction/materials/pressure relief), ventilation, electrical equipment, fire alarms,<<<<>>>>>conclusions of the report.\\nHuman: What is the purpose of section 2.7 in the document?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain > 3:chain:LLMChain > 4:llm:ChatOpenAI] [1.23s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I'm sorry, but there is no mention of section 2.7 in the given context. The document only mentions sections 6 and 7.\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"I'm sorry, but there is no mention of section 2.7 in the given context. The document only mentions sections 6 and 7.\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 253,\n",
      "      \"completion_tokens\": 31,\n",
      "      \"total_tokens\": 284\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain > 3:chain:LLMChain] [1.24s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"I'm sorry, but there is no mention of section 2.7 in the given context. The document only mentions sections 6 and 7.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain] [1.24s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"I'm sorry, but there is no mention of section 2.7 in the given context. The document only mentions sections 6 and 7.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA] [1.38s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"I'm sorry, but there is no mention of section 2.7 in the given context. The document only mentions sections 6 and 7.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but there is no mention of section 2.7 in the given context. The document only mentions sections 6 and 7.\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(examples[4][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f86eb6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "24c92c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "predictions = qa.apply(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e67f1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QAEvalChain evaluates question answer pairs\n",
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5176ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create above chain with language model. LLM will help do evaluation\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "062691fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get back graded outputs\n",
    "graded_outputs = eval_chain.evaluate(examples, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "74e0bee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Question: What is the title of the document?\n",
      "Real Answer: The title of the document is \"COMPARISON OF COMMERCIAL, STATE-OF-THE-ART, FOSSIL-BASED HYDROGEN PRODUCTION TECHNOLOGIES\".\n",
      "Predicted Answer: I'm sorry, but there is no clear title for the document based on the given context. The first line says \"This page intentionally left blank\" and the last line says \"Article x\", but there is no clear indication of what the article is about or what its title is.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 1:\n",
      "Question: Who funded the project mentioned in the document?\n",
      "Real Answer: The project was funded by the United States Department of Energy, National Energy Technology Laboratory, in part, through a site support contract.\n",
      "Predicted Answer: There are two different projects mentioned in the document, one funded by the European Commission and another funded by the United States Department of Energy. Can you please specify which project you are referring to?\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 2:\n",
      "Question: What was the purpose of peer reviewing the report mentioned in the document?\n",
      "Real Answer: The purpose of peer reviewing the report mentioned in the document was to ensure that the information presented is based on sound and credible science, considered technically proficient, properly documented, and compliant with established quality requirements.\n",
      "Predicted Answer: The purpose of peer reviewing the report mentioned in the document was to improve the report by providing valuable insights and identifying any errors or omissions.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 3:\n",
      "Question: What is the metadata associated with the document and what information does it provide?\n",
      "Real Answer: The metadata associated with the document includes the source location and the page number where the content is located. The source location is specified as \"\\\\Users\\\\markc\\\\Hydrogen\\\\ComparisonofCommercialStateofArtFossilBasedHydrogenProductionTechnologies_Lewis2022.pdf\" and the content is located on page 3.\n",
      "Predicted Answer: The given context does not provide any information about the metadata associated with the document. It only includes a disclaimer and acknowledgments.\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "Example 4:\n",
      "Question: What is the purpose of section 2.7 in the document?\n",
      "Real Answer: The purpose of section 2.7 in the document is to outline the environmental targets, including air emissions targets, water emissions targets, and carbon dioxide emissions.\n",
      "Predicted Answer: I'm sorry, but there is no mention of section 2.7 in the given context. The document only mentions sections 6 and 7.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 5:\n",
      "Question: What are the three cases described in the document related to hydrogen production?\n",
      "Real Answer: The three cases described in the document related to hydrogen production are Case 1 - Steam Methane Reforming Plant Without CO2 Capture Process, Case 2 - Steam Methane Reforming Plant with CO2 Capture Process, and Case 3 - Autothermal Reforming Plant with CO2 Capture Process.\n",
      "Predicted Answer: The document describes three cases related to hydrogen production using natural gas reforming plants. Case 1 and Case 2 use a steam methane reformer and differ in that Case 1 does not include CO2 capture while Case 2 does. The third case, Case 3, uses an autothermal reformer and employs CO2 capture.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 6:\n",
      "Question: What are some common process areas in gasification, according to the document?\n",
      "Real Answer: Some common process areas in gasification, according to the document, include coal receiving and storage, coal preparation and feed system, air separation unit, gasifier, raw gas cooling and particulate removal, quench gas compressor, syngas scrubber, water gas shift reactors, low temperature heat recovery, mercury removal, sulfur recovery/tail gas cleanup, slag handling, steam generation, process water systems, accessory electric plant, instrumentation and control, and miscellaneous systems.\n",
      "Predicted Answer: According to the document, some common process areas in gasification include coal receiving and storage, O2 supply, gas cleanup, and hydrogen production.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 7:\n",
      "Question: What is discussed in section 4.17.2 of the document?\n",
      "Real Answer: The environmental results summary of the gasification case is discussed in section 4.17.2 of the document.\n",
      "Predicted Answer: Section 4.17.2 of the document discusses the Environmental Results Summary.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 8:\n",
      "Question: What is the title of Exhibit ES-4 in the document?\n",
      "Real Answer: The title of Exhibit ES-4 in the document is \"CO2e life cycle emissions for all cases.\"\n",
      "Predicted Answer: The title of Exhibit ES-4 is \"CO2e life cycle emissions for all cases\".\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 9:\n",
      "Question: What is Exhibit 3-19 in the document about?\n",
      "Real Answer: Exhibit 3-19 in the document is about the MDEA CO2 capture process typical flow diagram for reforming plants.\n",
      "Predicted Answer: The context provided does not include any information about Exhibit 3-19.\n",
      "Predicted Grade: CORRECT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All below are output by the language mdoel\n",
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    print(\"Predicted Grade: \" + graded_outputs[i]['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0544ae3",
   "metadata": {},
   "source": [
    "## Key Questions/Concerns for Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "175e4298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What to do if predicted answers incorrect?\n",
    "# QAEvalChain spit out the same question multiple times\n",
    "# Try to access the UI that tracks what is going on \n",
    "#  under the hood (from langchain plus)\n",
    "# --generate flywheel of datapoints to learn from!!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dbfce8",
   "metadata": {},
   "source": [
    "### Try to query this new vectorstor database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5680fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What system design results in the lowest hydrogen breakeven cost? \\\n",
    "What is that cost in USD/kg? Is this with or without subsidies? Use markdown to describe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "860a705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"What is hydrogen? \\\n",
    "Use markdown to describe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f797b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"What is the largest potential end-use market for hydrogen? \\\n",
    "Use markdown to describe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f568fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "query4 = \"How does hydrogen compare to alternatives for long-duration energy storage? \\\n",
    "Use markdown to describe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b561445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query5 = \"What are ideal conditions for hydrogen in use as long duration storage? \\\n",
    "Use markdown to describe in fewer than 800 words in bulleted list and list hydrogen's top competitors.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "83e6eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query6 = \"You are an investor. What are ideal conditions and locations for hydrogen for use as long duration storage? \\\n",
    "Use markdown to describe in fewer than 800 words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "763e34d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query7 = \"Please describe how a PEM electrolyzer and alkaline electrolyzer work. \\\n",
    "Use markdown to describe in fewer than 800 words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9f463bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to gauge breadth and depth of model's knowledge\n",
    "\n",
    "query8 = \"Please tell me the most cost-effective ways to decarbonize with hydrogen and \\\n",
    "the applications which hydrogen is decarbonizing. Do this in markdown in a bulleted list.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "87d4f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query9 = \"Please list the highest TRL hydrogen production methods and the range of their levelized cost of production in USD/kg. \\\n",
    "Do this in markdown in a bulleted list.\"\n",
    "\n",
    "#Good response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c21ab7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "query10 = \"What clean energy technologies are most competitive with hydrogen? \\\n",
    "What technologies are complementary to hydrogen? Display results in markdown in a table.\"\n",
    "\n",
    "#Poor response - probably due to knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4faf4dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.178929567337036\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "| Most Competitive with Hydrogen | Complementary to Hydrogen |\n",
       "|--------------------------------|---------------------------|\n",
       "| Solutions that directly use electricity | Diverse and complementary energy networks |\n",
       "|                                   | Flexible complement to other low-carbon energy technologies such as batteries and renewables |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "response = index.query(query10, llm=llm)\n",
    "#response = qa_stuff.run(query)\n",
    "\n",
    "run_time = time.time()-start_time\n",
    "print(run_time)\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79203b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "According to the given context, the integration with electricity markets and cheap renewable power sources could help achieve low breakeven costs for electrolytic hydrogen. The lowest hydrogen breakeven cost could be achieved today via direct wholesale market participation, which is around $3/kg. However, direct wholesale access is currently prohibited in CAISO under state law, but it is permissible in other organized wholesale markets. The profitability of hydrogen production also depends on electrolyzer siting. The context does not mention whether this cost includes subsidies or not."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f8fd8d",
   "metadata": {},
   "source": [
    "####  Key Question/Concerns for Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2551381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting unclear answers when combining all four reports\n",
    "# Does not seem to be correctly parsing through the data\n",
    "# Can it not read tables?\n",
    "# Why can't it generate more accurate answers?\n",
    "\n",
    "# QAGenerateChain.from_llm -> generates same questions. How to get higher fidelity questions?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

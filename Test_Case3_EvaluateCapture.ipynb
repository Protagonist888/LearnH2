{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20cc6a13",
   "metadata": {},
   "source": [
    "# LangChain: Evaluation¶\n",
    "### Outline:\n",
    "* Example generation\n",
    "* Manual evaluation (and debuging)\n",
    "* LLM-assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b2ded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key:········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "import openai\n",
    "import time\n",
    "import markdown\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pickle\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358f8c3",
   "metadata": {},
   "source": [
    "# Create our QandA application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a4beefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "#PDF directory loader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "769cc14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283.0424733161926\n"
     ]
    }
   ],
   "source": [
    "# file = 'GlobalPowerPlantDB_USonly.csv'\n",
    "start_time = time.time()\n",
    "\n",
    "pdf_folder_path = \"/Users/markc/Hydrogen/\"\n",
    "loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
    "data = loader.load_and_split()\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "run_time = end_time-start_time\n",
    "print(run_time)\n",
    "\n",
    "# For 3900 pages...\n",
    "#loader.load() takes 137 sec. \n",
    "#loader.load_and_split() takes 129 sec.6800 pgs -> 300s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c0ee9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6864"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(data))\n",
    "data[111]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b7dde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13728"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.astype(str)\n",
    "df.rename(columns={0: 'input', 1: 'metadata'},inplace=True)\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88caff68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  \\\n",
      "0  ('page_content', '1 \\n \\nComparison of hydroge...   \n",
      "1  ('page_content', '2 \\n \\n \\n \\n1. Vehicle char...   \n",
      "2  ('page_content', '3 \\n \\n \\nThe energy consump...   \n",
      "3  ('page_content', \"4 \\n \\n2. Duty cycles  \\nThe...   \n",
      "4  ('page_content', \"5 \\n \\n \\n \\nVehicle costs  ...   \n",
      "5  ('page_content', \"6 \\n \\nGHG emissions). Depen...   \n",
      "6  ('page_content', '7 \\n \\n \\n \\n \\nElectricity ...   \n",
      "7  ('page_content', '8 \\n \\nhydrogen refuelling \\...   \n",
      "8  ('page_content', '9 \\n \\nService life  15 year...   \n",
      "9  ('page_content', \"10 \\n \\n3.4. Road charges  \\...   \n",
      "\n",
      "                                            metadata  \n",
      "0  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "1  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "2  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "3  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "4  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "5  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "6  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "7  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "8  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "9  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n"
     ]
    }
   ],
   "source": [
    "# Convert columns to string so to_parquet will work\n",
    "df[df.columns[0]]=df[df.columns[0]].astype(str)\n",
    "df[df.columns[1]]=df[df.columns[1]].astype(str)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1601a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenny from Estuary notes Parquet is \"not easy to work with\" so will try JSON format. \n",
    "# df.to_parquet('data.parquet')\n",
    "\n",
    "#convert to dataframe to JSON file\n",
    "json_data = df.to_json(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5425418",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as file:\n",
    "    file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbfd9abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 858319 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 908847 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 832668 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 893572 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 818813 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 878481 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 917801 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 840675 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 763445 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 861992 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 786861 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 876910 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 802310 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 841214 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 917219 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 842037 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 913179 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 837445 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 884371 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 809452 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 884495 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 808182 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 879632 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 924951 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 846726 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 915821 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 841620 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492.78683376312256\n"
     ]
    }
   ],
   "source": [
    "# Efficient vectorstor method?\n",
    "# Setting vector indices for data\n",
    "start_time = time.time()\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])\n",
    "\n",
    "end_time = time.time()\n",
    "run_time = end_time-start_time\n",
    "print(run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02d00bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why does chain_type not accept map_reduce?\n",
    "llm = ChatOpenAI(temperature = 0.0)\n",
    "qa = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=index.vectorstore.as_retriever(), \n",
    "    verbose=True,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs = {\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f22e2",
   "metadata": {},
   "source": [
    "# Coming up with test datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6230250a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='116 The effect on the lifecycle GHG emissions associated with LUC  for the corn ethanol (E85 CURRENT \\nTECHNOLOGY , HIGH VOLUME  case) , FAME, and HRD pathway s are discussed in Section  8.1. Since the \\ncost of avoided GHG emissions depend s on different assumptions made regarding LUC -associated GHG \\nemissions, a sensitivity analysis was conducted to characterize the impact of varying LUC  assumptions on \\nthe cost of avoided carbon m etric for the E85 pathway for the C URRENT TECHNOLOGY , HIGH VOLUME  \\ncase and the FAME (B20) and HRD pathways for the FUTURE  TECHNOLOGY , HIGH VOLUME  case. \\nFigure  39 shows the range of costs of avoided GHG emissions assuming no LUC  and high LUC, as well \\nas the base case results for these pathways.  \\nFor the E85 C URRENT TECHNOLOGY  case,  the no -LUC sensitivity has lifecycle emissions of 3 40 g \\nCO 2e/mi. EPA ( 2010c) represents the high estimate of LUC  that still yields GHG reductions (lifecycle \\nemissions of 434 g CO 2e/mi). For E85, Searchinger  et al.  (2008) estimates larger LUC -related emissions, \\nleading to lifecycle GHG emissions of 6 85 g CO 2e/mi. As this level of  emissions exceeds the emissions of \\na conventional gasoline ICEV, no emissions reductions are associated with E85 use when this level of \\nLUC -induced emissions are assumed, leading to an infinite cost of reduced avoided carbon emissions \\n(shown as a dotted l ine in the figure) . For the FAME (B20) and HRD (B100) F UTURE  TECHNOLOGY  \\npathways , LUC data from  Section 8.1  do not show a significant variance from the LUC -related emissions \\nthat are captured in GREET . For these pathways, a sensitivity analysis was conducted to understand the \\neffect if no LUC -related emissions are considered.  \\n \\n \\nFigure 39. Effect of different LUC assumptions on the cost of avoided GHG emissions for the E85 , FAME, \\nand HRD  pathway s', metadata={'source': '\\\\Users\\\\markc\\\\Hydrogen\\\\ANL_ESD-16dash7_LCAemissions.pdf', 'page': 142})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[410]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38eecccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6864"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8661bc8a",
   "metadata": {},
   "source": [
    "# LLM-Generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ec7977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four boxes below generate Q&A pair to evaluate model\n",
    "from langchain.evaluation.qa import QAGenerateChain\n",
    "\n",
    "# Pass in OpenIA language model to interact with chain\n",
    "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37eb538d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not parse output: QUESTION: What is the title of the document?\n\nANSWER: The title of the document is \"Comparison of hydrogen and battery electric trucks\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get back dictionary of question/answer pairs to evaluate\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m new_examples \u001b[38;5;241m=\u001b[39m \u001b[43mexample_gen_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_and_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdoc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:257\u001b[0m, in \u001b[0;36mLLMChain.apply_and_parse\u001b[1;34m(self, input_list, callbacks)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call apply and then parse the results.\"\"\"\u001b[39;00m\n\u001b[0;32m    256\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(input_list, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:263\u001b[0m, in \u001b[0;36mLLMChain._parse_result\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_result\u001b[39m(\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m, result: List[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]\n\u001b[0;32m    261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence[Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39moutput_parser \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    264\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39moutput_parser\u001b[38;5;241m.\u001b[39mparse(res[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]) \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result\n\u001b[0;32m    265\u001b[0m         ]\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\langchain\\chains\\llm.py:264\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_result\u001b[39m(\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m, result: List[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]\n\u001b[0;32m    261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence[Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39moutput_parser \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 264\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result\n\u001b[0;32m    265\u001b[0m         ]\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\langchain\\output_parsers\\regex.py:28\u001b[0m, in \u001b[0;36mRegexParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_output_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     31\u001b[0m             key: text \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_output_key \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys\n\u001b[0;32m     33\u001b[0m         }\n",
      "\u001b[1;31mValueError\u001b[0m: Could not parse output: QUESTION: What is the title of the document?\n\nANSWER: The title of the document is \"Comparison of hydrogen and battery electric trucks\"."
     ]
    }
   ],
   "source": [
    "# Get back dictionary of question/answer pairs to evaluate\n",
    "#\n",
    "new_examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t} for t in data[:10]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3416dfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Since the publication of the 2021 Annual Evaluation, there have been a total of 8 new Open-Retail hydrogen fueling stations added to California's network, 6 of which opened in 2022.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See example\n",
    "new_examples[9]\n",
    "\n",
    "examples = []\n",
    "examples += new_examples\n",
    "\n",
    "qa.run(examples[9][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69b17e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b51a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Since the 2021 Annual Evaluation was published, a total of 8 new Open-Retail hydrogen fueling stations have been added to California's network, 6 of which opened in 2022.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "289ecafa",
   "metadata": {},
   "source": [
    "# Manual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40993c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "638d5879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Where was the source of the document located?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain > 3:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Where was the source of the document located?\",\n",
      "  \"context\": \"by-product sources.<<<<>>>>>information. Web posting. Summaries. \\nVerDate Sep 11 2014 12:25 Dec 28, 2021 Jkt 029139 PO 00058 Frm 00314 Fmt 6580 Sfmt 6581 E:\\\\PUBLAW\\\\PUBL058.117 PUBL058whamilton on LAPJF8D0R2PROD with PUBLAW<<<<>>>>>note. Records. Estimate. \\nVerDate Sep 11 2014 12:25 Dec 28, 2021 Jkt 029139 PO 00058 Frm 00345 Fmt 6580 Sfmt 6581 E:\\\\PUBLAW\\\\PUBL058.117 PUBL058whamilton on LAPJF8D0R2PROD with PUBLAW<<<<>>>>>1992 -UC-38; Pacific Northwest Laborator y: Richland, W A; 1976 .\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain > 3:chain:LLMChain > 4:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Use the following pieces of context to answer the users question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\nby-product sources.<<<<>>>>>information. Web posting. Summaries. \\nVerDate Sep 11 2014 12:25 Dec 28, 2021 Jkt 029139 PO 00058 Frm 00314 Fmt 6580 Sfmt 6581 E:\\\\PUBLAW\\\\PUBL058.117 PUBL058whamilton on LAPJF8D0R2PROD with PUBLAW<<<<>>>>>note. Records. Estimate. \\nVerDate Sep 11 2014 12:25 Dec 28, 2021 Jkt 029139 PO 00058 Frm 00345 Fmt 6580 Sfmt 6581 E:\\\\PUBLAW\\\\PUBL058.117 PUBL058whamilton on LAPJF8D0R2PROD with PUBLAW<<<<>>>>>1992 -UC-38; Pacific Northwest Laborator y: Richland, W A; 1976 .\\nHuman: Where was the source of the document located?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain > 3:chain:LLMChain > 4:llm:ChatOpenAI] [2.33s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The source of the document is not specified.\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"The source of the document is not specified.\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 260,\n",
      "      \"completion_tokens\": 9,\n",
      "      \"total_tokens\": 269\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain > 3:chain:LLMChain] [2.33s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"The source of the document is not specified.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain] [2.33s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"The source of the document is not specified.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA] [2.96s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"The source of the document is not specified.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The source of the document is not specified.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(examples[4][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f86eb6c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'langchain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlangchain\u001b[49m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'langchain' is not defined"
     ]
    }
   ],
   "source": [
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24c92c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "predictions = qa.apply(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e67f1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QAEvalChain evaluates question answer pairs\n",
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5176ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create above chain with language model. LLM will help do evaluation\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "062691fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'examples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get back graded outputs\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m graded_outputs \u001b[38;5;241m=\u001b[39m eval_chain\u001b[38;5;241m.\u001b[39mevaluate(\u001b[43mexamples\u001b[49m, predictions)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'examples' is not defined"
     ]
    }
   ],
   "source": [
    "# Get back graded outputs\n",
    "graded_outputs = eval_chain.evaluate(examples, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74e0bee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Question: What is the title of the report and what legislation is it pursuant to?\n",
      "Real Answer: The title of the report is \"2022 Annual Evaluation of Fuel Cell Electric Vehicle Deployment and Hydrogen Fuel Station Network Development\" and it is pursuant to Assembly Bill 8, also known as Perea, Chapter 401, Statutes of 2013.\n",
      "Predicted Answer: The context does not provide a clear answer to this question. However, it mentions several reports that the Secretary and Chiefs are required to submit to Congress, including a report with recommendations to Congress relating to the Program, a report describing methods, and additional reports for fiscal years 2022 and 2023. The legislation that these reports are pursuant to is also not specified in the context.\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "Example 1:\n",
      "Question: Who reviewed and approved the report for publication?\n",
      "Real Answer: The staff of the California Air Resources Board (CARB) reviewed and approved the report for publication.\n",
      "Predicted Answer: The report was reviewed by a panel of expert peer reviewers, including Professor Jack Brouwer, Professor Michael Kuby, Dr. Marc Melaina, Professor Joan Ogden, and Michael Penev, MBA, as well as several other reviewers listed in the context. However, it is not specified who approved the report for publication.\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "Example 2:\n",
      "Question: What is CARB's mission statement?\n",
      "Real Answer: CARB's mission is to promote and protect public health, welfare, and ecological resources through effective reduction of air pollutants while recognizing and considering effects on the economy.\n",
      "Predicted Answer: CARB's mission is to promote and protect public health, welfare, and ecological resources through effective reduction of air pollutants while recognizing and considering effects on the economy. CARB is the lead agency for climate change programs and oversees all air pollution control efforts in California to attain and maintain health-based air quality standards.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 3:\n",
      "Question: What is the purpose of the document mentioned in the metadata?\n",
      "Real Answer: The purpose of the document mentioned in the metadata is to provide information and analysis on the progress, provisions, and developments related to hydrogen fueling infrastructure in California.\n",
      "Predicted Answer: I'm sorry, but I cannot determine the document you are referring to as there is no mention of a specific document in the metadata provided. The metadata only includes snippets of text from different sections of different documents, making it difficult to determine the purpose of any specific document. Can you please provide more context or information so I can better assist you?\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 4:\n",
      "Question: Where was the source of the document located?\n",
      "Real Answer: The source of the document was located in the file path '\\\\Users\\\\markc\\\\Hydrogen\\\\AB-8-Report-2022_CARB.pdf'.\n",
      "Predicted Answer: The source of the document is not specified.\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "Example 5:\n",
      "Question: What does the acronym \"LCFS\" stand for?\n",
      "Real Answer: \"LCFS\" stands for \"Low Carbon Fuel Standard\".\n",
      "Predicted Answer: The acronym \"LCFS\" stands for \"Low Carbon Fuel Standard\".\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 6:\n",
      "Question: What is the source of the document and on which page is the content located?\n",
      "Real Answer: The source of the document is '\\\\Users\\\\markc\\\\Hydrogen\\\\AB-8-Report-2022_CARB.pdf' and the content is located on page 6.\n",
      "Predicted Answer: The source of the document is not specified and there is no content located on the page as it is intentionally left blank.\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "Example 7:\n",
      "Question: What is the goal of the Advanced Clean Cars II (ACC II) regulation proposed by the California Air Resources Board (CARB)?\n",
      "Real Answer: The goal of the Advanced Clean Cars II (ACC II) regulation proposed by the California Air Resources Board (CARB) is to achieve 100 percent zero-emission vehicle (ZEV) sales of new light-duty vehicles in California by 2035, as outlined in Governor Newsom’s Executive Order (EO) N-79-20.\n",
      "Predicted Answer: The goal of the Advanced Clean Cars II (ACC II) regulation proposed by the California Air Resources Board (CARB) is to achieve 100 percent zero-emission vehicle (ZEV) sales of new light-duty vehicles in California by 2035, as outlined by Governor Newsom's Executive Order (EO) N-79-20. This regulation aims to enable a transition to zero-emission transportation across all transportation sectors in California, including light-duty, medium-duty, heavy-duty, on-road, and off-road vehicles.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 8:\n",
      "Question: What is the purpose of California's Assembly Bill 8?\n",
      "Real Answer: California's Assembly Bill 8 (AB 8) provides the Energy Commission with up to $20 million annually through the end of 2023 to co-fund the development of hydrogen fueling stations in California. The goal is to address the hurdle of fueling infrastructure and ensure that FCEV use expands and becomes a viable ZEV option for an increasing number of Californians in the future. AB 8 requires that reports provide analysis of current and projected future FCEV deployment and hydrogen fueling station development and identify needs for further hydrogen station network development.\n",
      "Predicted Answer: The purpose of California's Assembly Bill 8 is to provide a financial resource to several programs through a fee applied to vehicle and vessel registrations, and to support the development and deployment of advanced transportation and fuel technologies, including supporting infrastructure for both hydrogen-fueled fuel cell electric vehicles (FCEVs) and electrically charged battery electric vehicles. The program was extended in 2013 with new provisions to co-fund the development of public hydrogen fueling stations.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 9:\n",
      "Question: How many new hydrogen fueling stations achieved Open-Retail status in California since the publication of the 2021 Annual Evaluation?\n",
      "Real Answer: Eight new hydrogen fueling stations achieved Open-Retail status in California since the publication of the 2021 Annual Evaluation.\n",
      "Predicted Answer: Since the publication of the 2021 Annual Evaluation, there have been a total of 8 new Open-Retail hydrogen fueling stations added to California's network, 6 of which opened in 2022.\n",
      "Predicted Grade: CORRECT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All below are output by the language mdoel\n",
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    print(\"Predicted Grade: \" + graded_outputs[i]['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0544ae3",
   "metadata": {},
   "source": [
    "## Key Questions/Concerns for Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "175e4298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What to do if predicted answers incorrect?\n",
    "# QAEvalChain spit out the same question multiple times\n",
    "# Try to access the UI that tracks what is going on \n",
    "#  under the hood (from langchain plus)\n",
    "# --generate flywheel of datapoints to learn from!!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dbfce8",
   "metadata": {},
   "source": [
    "### Try to query this new vectorstor database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5680fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What system design results in the lowest hydrogen breakeven cost? \\\n",
    "What is that cost in USD/kg? Is this with or without subsidies? Use markdown to describe.\"\n",
    "\n",
    "# Decent answer. High level, but limited by propmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "860a705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"What are the major challenges to deploying hydrogen and how can they become overcome?. \\\n",
    "Use bulleted markdown list to describe.\"\n",
    "\n",
    "# Decent answer. Relatively high level. Same as ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f797b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"I wish to deploy hydrogen production in California. What technology should I use, where shoult it be placed,  \\\n",
    "what commercial models are suggested, and what federal or state incentives are applicable? Use markdown to describe.\"\n",
    "\n",
    "# Not a good answer. Very generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f568fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "query4 = \"What federal incentives exist for hydrogen production? \\\n",
    "Use markdown to describe.\n",
    "\n",
    "# Not specific enough answer. ChatGPT has better answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b561445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query5 = \"What are ideal conditions for hydrogen in use as long duration storage? \\\n",
    "Use markdown to describe in fewer than 800 words in bulleted list and list hydrogen's top competitors.\"\n",
    "\n",
    "# Good answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "83e6eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query6 = \"You are an investor. What are ideal conditions and locations for hydrogen for use as long duration storage? \\\n",
    "Use markdown to describe in fewer than 800 words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "763e34d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query7 = \"Please describe how a PEM electrolyzer, alkaline electrolyzer, and solid oxide electrolyzer work. What are advantages and disadvantages for each? \\\n",
    "What is the average levelized cost of hydrogen production (in USD/kg) for each? Use markdown to describe in fewer than 1000 words.\"\n",
    "\n",
    "# Good answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f463bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to gauge breadth and depth of model's knowledge\n",
    "\n",
    "query8 = \"Please tell me the most cost-effective, scalable ways to decarbonize with hydrogen and \\\n",
    "the applications which hydrogen is most competitive in  decarbonizing. Do this in markdown in a bulleted list.\"\n",
    "\n",
    "# Decent answer. Lacks a bit of detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "87d4f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query9 = \"Please list the highest TRL hydrogen production methods and the range of their levelized cost of production in USD/kg. \\\n",
    "Do this in markdown in a bulleted list.\"\n",
    "\n",
    "#Good response. Same as ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c21ab7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "query10 = \"What clean energy technologies are most competitive with hydrogen? \\\n",
    "What technologies are complementary to hydrogen? Display results in markdown in a table.\"\n",
    "\n",
    "#Poor response - probably due to knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b82d98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query11 = \"What are the main hydrogen provisions in the Clean Hydrogen Act? \\\n",
    "Create a bulleted list with short description. Display results in markdown in a table.\"\n",
    "\n",
    "#Poor response - probably due to knowledge base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d796d08b",
   "metadata": {},
   "source": [
    "### Added questions with larger database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33253d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query12 = \"Describe in details what the optimal path is to decarbonize California's grid. \\\n",
    "provide detail in no more than 1000 words and use a bulleted list in markdown to describe. \\\n",
    "What are the main renewable technologies California plans to use?\"\n",
    "\n",
    "# Decent answer, but very high level. Might be a result of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16afa30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query13 = \"What are the major challenges in using hydrogen in existing existing oil & gas infrastructure? \\\n",
    " Provide a response in fewer than 1500 words using markdown.\"\n",
    "\n",
    "# Great answer. Slightly better than ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cbddfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query14 = \"Describe hydrogen's main physical characteristics such as flammability range, energy density, ignition energy, etc. \\\n",
    "Include the top 10 most cited physical characteristics and output in markdwon table.\"\n",
    "\n",
    "# Wow! Great answer. Same as ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d69335ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query15 = \"How does the cost of producing hydrogen from electrolysis compare with SMR w/CCS? \\\n",
    "Are there any particular regions in the US where electrolytic hydrogen is more cost effective? What makes that so? \\\n",
    "Provide an answer in bulleted list form in markdown. \"\n",
    "\n",
    "# Not a great answer. I feel prompt may be too generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c203c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "query16 = \"How should I think about deploying cost-effective electrolytic hydrogen? What are the major considerations? \\\n",
    "Provide an answer in bulleted list form in markdown. \"\n",
    "\n",
    "# Good answer. Same as ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1919d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "query17 = \"What are some ways to invest in the hydrogen market? Briefly describe each opportunity \\\n",
    "Provide an answer in bulleted list form in markdown in fewer than 1000 words. \"\n",
    "\n",
    "# Good answer. Nearly same as ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90b18ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query18 = \"Describe how CCS and CCUS work. What is the approximate cost of each technology? How do they pair with  \\\n",
    "hydrogen technologies? Provide an answer in bulleted list form in markdown in fewer than 1000 words. \"\n",
    "\n",
    "# Good answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ad041fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query19 = \"Describe the key differences between SMR and ATR. What are they? Which process is more efficient? \\\n",
    "Which technology is more cost effective? Provide an answer in bulleted list form in markdown in fewer than 1000 words. \"\n",
    "\n",
    "# Good answer. About same as ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "604e7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query20 = \"What carbon capture technologies should I consider for a SMR unit? How about for an ATR unit? \\\n",
    "What are the advantages and disadvantages for each carbon capture technology when paired with SMR or ATR? \\\n",
    "Provide an answer in bulleted list form in markdown in fewer than 2000 words. \"\n",
    "\n",
    "# Good answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d73c954",
   "metadata": {},
   "outputs": [],
   "source": [
    "query21 = \"How much does it cost to construct a natural gas pipeline? How about a hydrogen pipeline? \\\n",
    "What are the major differenences between the two? \\\n",
    "Provide an answer in bulleted list in markdown in fewer than 2000 words. \"\n",
    "\n",
    "# very mediocre answer. Need more depth here in this topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8c847d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query22 = \"How does liquefaction of hydrogen work? What is the cost of liquefaction at various scales? \\\n",
    "In what scenarios is gaseous delivery of hydrogen less economic the delivery of liquid hydrogen? \\\n",
    "Provide an answer in a bulleted list form in markdown in fewer than 1500 words. \"\n",
    "\n",
    "# Pretty good 1st order answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bfb14eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query23 = \"Provide an overview of the various hydrogen carriers that could be used to transport hydrogen. \\\n",
    "How do the costs of each carrier compare? In what scnearios is one carrier favored over others? \\\n",
    "Provide an answer in a table form in markdown in fewer than 1500 words. \"\n",
    "\n",
    "# Pretty good 1st order answer. About the same as ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cb016dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query24 = \"Provide an overview of how natural hydrogen is produced. What are the processes? Where can it be found? \\\n",
    "Provide an answer in a table form in markdown in fewer than 1500 words. \"\n",
    "\n",
    "# Pretty good 1st order answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "346126c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query25 = \"Provide an in-depth review of how natural hydrogen occurs. What are the different processes? Where can it be found? \\\n",
    "Provide an answer in a table form in markdown in fewer than 3000 words. \"\n",
    "\n",
    "# Not a great answer. Why is this? ChatGPT's answer is far worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4faf4dfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'question'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      2\u001b[0m response \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mquery(query19, llm\u001b[38;5;241m=\u001b[39mllm)\n\u001b[1;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mqa\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery19\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#response = qa_stuff.run(query)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m run_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart_time\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\langchain\\chains\\base.py:128\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, include_run_info)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    108\u001b[0m     inputs: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Any],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m     include_run_info: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    113\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    114\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the logic of this chain and add to output if desired.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m            to False.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m     callback_manager \u001b[38;5;241m=\u001b[39m CallbackManager\u001b[38;5;241m.\u001b[39mconfigure(\n\u001b[0;32m    130\u001b[0m         callbacks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose\n\u001b[0;32m    131\u001b[0m     )\n\u001b[0;32m    132\u001b[0m     new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\langchain\\chains\\base.py:236\u001b[0m, in \u001b[0;36mChain.prep_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    234\u001b[0m     external_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mload_memory_variables(inputs)\n\u001b[0;32m    235\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexternal_context)\n\u001b[1;32m--> 236\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\langchain\\chains\\base.py:83\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     81\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Missing some input keys: {'question'}"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "response = index.query(query19, llm=llm)\n",
    "result = qa({\"query\": query19})\n",
    "#response = qa_stuff.run(query)\n",
    "\n",
    "run_time = time.time()-start_time\n",
    "print(run_time)\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79203b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "According to the given context, the integration with electricity markets and cheap renewable power sources could help achieve low breakeven costs for electrolytic hydrogen. The lowest hydrogen breakeven cost could be achieved today via direct wholesale market participation, which is around $3/kg. However, direct wholesale access is currently prohibited in CAISO under state law, but it is permissible in other organized wholesale markets. The profitability of hydrogen production also depends on electrolyzer siting. The context does not mention whether this cost includes subsidies or not."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa37cb",
   "metadata": {},
   "source": [
    "### Section to test out returning citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc613a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "docsearch = Chroma.from_texts(texts, embeddings, m )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5169410",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docsearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m qa \u001b[38;5;241m=\u001b[39m RetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(llm\u001b[38;5;241m=\u001b[39mllm, chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m----> 2\u001b[0m                                 retriever\u001b[38;5;241m=\u001b[39m\u001b[43mdocsearch\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(),\n\u001b[0;32m      3\u001b[0m                                 return_source_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'docsearch' is not defined"
     ]
    }
   ],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\",\n",
    "                                retriever=docsearch.as_retriever(),\n",
    "                                return_source_documents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f8fd8d",
   "metadata": {},
   "source": [
    "####  Key Question/Concerns for Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2551381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting unclear answers when combining all four reports\n",
    "# Does not seem to be correctly parsing through the data\n",
    "# Can it not read tables?\n",
    "# Why can't it generate more accurate answers?\n",
    "\n",
    "# QAGenerateChain.from_llm -> generates same questions. How to get higher fidelity questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c362a4a2",
   "metadata": {},
   "source": [
    "### List of topics to add\n",
    "\n",
    "* Transportation economics\n",
    "* Natural hydrogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dcc193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20cc6a13",
   "metadata": {},
   "source": [
    "# LangChain: EvaluationÂ¶\n",
    "### Outline:\n",
    "* Example generation\n",
    "* Manual evaluation (and debuging)\n",
    "* LLM-assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b2ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import openai\n",
    "import time\n",
    "import markdown\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pickle\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\"\"\"\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')\n",
    "OPEN_API_KEY = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358f8c3",
   "metadata": {},
   "source": [
    "# Create our QandA application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4beefd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DocArrayInMemorySearch' from 'langchain.vectorstores' (C:\\Users\\markc\\miniconda3\\lib\\site-packages\\langchain\\vectorstores\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyPDFLoader\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorstoreIndexCreator\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocArrayInMemorySearch\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#PDF directory loader\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyPDFDirectoryLoader\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DocArrayInMemorySearch' from 'langchain.vectorstores' (C:\\Users\\markc\\miniconda3\\lib\\site-packages\\langchain\\vectorstores\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "#PDF directory loader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22782a16",
   "metadata": {},
   "source": [
    "## Load PDF data and split\n",
    "* (1) Loads all PDFs in a directory\n",
    "* (2) Splits text into chunks (however, this method should be revisited)\n",
    "* (3) Creates a dataframe with index\n",
    "* (4) Creates .JSON with the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769cc14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722.7222647666931\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Change path to /Hydrogen_mini for quicker tests\n",
    "pdf_folder_path = \"/Users/markc/Hydrogen/\"\n",
    "loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
    "data = loader.load_and_split()\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "run_time = end_time-start_time\n",
    "print(run_time)\n",
    "\n",
    "# For 3900 pages...\n",
    "#loader.load() takes 137 sec. \n",
    "#loader.load_and_split() takes 755 sec for 14830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c0ee9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15108"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(data))\n",
    "data[111]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b7dde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30216"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.astype(str)\n",
    "df.rename(columns={0: 'input', 1: 'source'},inplace=True)\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88caff68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  \\\n",
      "0  ('page_content', 'Joule, Volume 7\\nSupplementa...   \n",
      "1  ('page_content', 'Supplementa l Figures:  \\n \\...   \n",
      "2  ('page_content', 'Figure S2: LCOH of steam boi...   \n",
      "3  ('page_content', 'Figure S 3: Efficiency and c...   \n",
      "4  ('page_content', 'Figure S4: LCOH for industri...   \n",
      "5  ('page_content', 'Figure S 5: Comparison of (a...   \n",
      "6  ('page_content', 'Figure S6: LCOH of steam boi...   \n",
      "7  ('page_content', 'Figure S 7: Possible variati...   \n",
      "8  ('page_content', 'Figure S 8: Variation of LCO...   \n",
      "9  ('page_content', 'Figure S 9: State -level des...   \n",
      "\n",
      "                                              source  \n",
      "0  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "1  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "2  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "3  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "4  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "5  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "6  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "7  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "8  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n",
      "9  ('metadata', {'source': '\\\\Users\\\\markc\\\\Hydro...  \n"
     ]
    }
   ],
   "source": [
    "# Convert columns to string so to_parquet will work\n",
    "df[df.columns[0]]=df[df.columns[0]].astype(str)\n",
    "df[df.columns[1]]=df[df.columns[1]].astype(str)\n",
    "df.set_index(pd.Index(range(len(df))), inplace=True)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1601a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenny from Estuary notes Parquet is \"not easy to work with\" so will try JSON format. \n",
    "# df.to_parquet('data.parquet')\n",
    "\n",
    "#convert to dataframe to JSON file\n",
    "json_data = df.to_json(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5425418",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as file:\n",
    "    file.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bef969e",
   "metadata": {},
   "source": [
    "### Create vector stor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbfd9abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 919734 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 837755 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 892914 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 812337 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 908077 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 830553 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 891543 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 811639 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 848165 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 895616 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 817846 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 855816 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 901155 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 824004 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 850369 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 884249 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 917465 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 826425 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 881442 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 803833 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 857319 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 889907 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 809729 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 880682 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 798095 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 884202 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 806056 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 889609 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 808747 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 872698 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 795523 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 864875 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 927662 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 848043 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 884850 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 796866 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 843383 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 880947 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 800557 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 847480 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 882094 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 803631 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 861967 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 890854 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 810700 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 850345 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 767496 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 861321 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 781706 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 818111 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 880547 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 791089 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 856613 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 904708 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 924503 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 843265 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 893242 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 814053 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 885457 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 802419 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 870663 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 940240 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-0QB3BCHxO2VYRI58a5rutnKr on tokens per min. Limit: 1000000 / min. Current: 862133 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1236.26917886734\n"
     ]
    }
   ],
   "source": [
    "# Efficient vectorstor method?\n",
    "# Setting vector indices for data\n",
    "start_time = time.time()\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])\n",
    "\n",
    "end_time = time.time()\n",
    "run_time = end_time-start_time\n",
    "print(run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02d00bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why does chain_type not accept map_reduce?\n",
    "llm = ChatOpenAI(temperature = 0.0)\n",
    "qa = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=index.vectorstore.as_retriever(), \n",
    "    verbose=True,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs = {\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f22e2",
   "metadata": {},
   "source": [
    "# Check dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6230250a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='result of the methodological change in the German EU-SILC survey approach.\\n(23) European Commission (2020), Joint Employment Report 2021 , Directorate-General for Employment, Social \\nAffairs and Inclusion, Brussels.  The data in this report refer to the EU including the UK.\\n(24) European Commission (2010), The European Platform against Poverty and Social Exclusion: A European \\nframework for social and territorial cohesion , COM(2010) 0758 final.\\n(25) Source: Eurostat (online data code: ilc_lvho07a ).\\n(26) Source: Eurostat (online data code: hlth_dhc060 ).\\n(27) A household is considered overcrowded if it does not have at least one room for the entire household as \\nwell as a room for a couple, for each single person above 18, for a pair of teenagers (12 to 17 years of age) of \\nthe same sex, for each teenager of different sex and for a pair of children (under 12 years of age).\\n(28) Source: Eurostat (online data code: ilc_mdho06a ).\\n(29) Source: Eurostat (online data codes: ilc_lvho07d  and ilc_mdho06d ).\\n(30) Source: Eurostat (online data code: hlth_silc_08 ).\\n(31) The equivalised disposable income is the total income of a household, after tax and other deductions, that \\nis available for spending or saving, divided by the number of household members converted into equalised \\nadults; household members are equalised or made equivalent by weighting each according to their age, \\nusing the so-called modified OECD equivalence scale.', metadata={'source': '\\\\Users\\\\markc\\\\Hydrogen\\\\2021 - Sustainable development in the European Union mon.pdf', 'page': 53})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[410]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38eecccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14830"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f86eb6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0544ae3",
   "metadata": {},
   "source": [
    "## Key Questions/Concerns for Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "175e4298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What to do if predicted answers incorrect?\n",
    "# QAEvalChain spit out the same question multiple times\n",
    "# Try to access the UI that tracks what is going on \n",
    "#  under the hood (from langchain plus)\n",
    "# --generate flywheel of datapoints to learn from!!!!\n",
    "# Pretrain vectordatabase with Estuary/Pinecone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dbfce8",
   "metadata": {},
   "source": [
    "### Try to query this new vectorstor database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5680fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What system design results in the lowest hydrogen breakeven cost? \\\n",
    "What is that cost in USD/kg? Is this with or without subsidies? Use markdown to describe.\"\n",
    "\n",
    "# Decent answer. High level, but limited by propmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "860a705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"What are the major challenges to deploying hydrogen and how can they become overcome?. \\\n",
    "Use bulleted markdown list to describe.\"\n",
    "\n",
    "# Decent answer. Relatively high level. Same as ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f797b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"I wish to deploy hydrogen production in California. What technology should I use, where shoult it be placed,  \\\n",
    "what commercial models are suggested, and what federal or state incentives are applicable? Use markdown to describe.\"\n",
    "\n",
    "# Not a good answer. Very generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f568fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "query4 = \"What federal incentives exist for hydrogen production? \\\n",
    "Use markdown to describe.\"\n",
    "\n",
    "# Not specific enough answer. ChatGPT has better answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b561445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query5 = \"What are ideal conditions for hydrogen in use as long duration storage? \\\n",
    "Use markdown to describe in fewer than 800 words in bulleted list and list hydrogen's top competitors.\"\n",
    "\n",
    "# Good answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83e6eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query6 = \"You are an investor. What are ideal conditions and locations for hydrogen for use as long duration storage? \\\n",
    "Use markdown to describe in fewer than 800 words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "763e34d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query7 = \"Please describe how a PEM electrolyzer, alkaline electrolyzer, and solid oxide electrolyzer work. What are advantages and disadvantages for each? \\\n",
    "What is the average levelized cost of hydrogen production (in USD/kg) for each? Use markdown to describe in fewer than 1000 words.\"\n",
    "\n",
    "# Good answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f463bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to gauge breadth and depth of model's knowledge\n",
    "\n",
    "query8 = \"Please tell me the most cost-effective, scalable ways to decarbonize with hydrogen and \\\n",
    "the applications which hydrogen is most competitive in  decarbonizing. Do this in markdown in a bulleted list.\"\n",
    "\n",
    "# Decent answer. Lacks a bit of detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87d4f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query9 = \"Please list the highest TRL hydrogen production methods and the range of their levelized cost of production in USD/kg. \\\n",
    "Do this in markdown in a bulleted list.\"\n",
    "\n",
    "#Good response. Same as ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c21ab7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "query10 = \"What clean energy technologies are most competitive with hydrogen? \\\n",
    "What technologies are complementary to hydrogen? Display results in markdown in a table.\"\n",
    "\n",
    "#Poor response - probably due to knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b82d98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query11 = \"What are the main hydrogen provisions in the Clean Hydrogen Act? \\\n",
    "Create a bulleted list with short description. Display results in markdown in a table.\"\n",
    "\n",
    "#Poor response - probably due to knowledge base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d796d08b",
   "metadata": {},
   "source": [
    "### Added questions with larger database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33253d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query12 = \"Describe in details what the optimal path is to decarbonize California's grid. \\\n",
    "provide detail in no more than 1000 words and use a bulleted list in markdown to describe. \\\n",
    "What are the main renewable technologies California plans to use?\"\n",
    "\n",
    "# Decent answer, but very high level. Might be a result of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16afa30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query13 = \"What are the major challenges in using hydrogen in existing existing oil & gas infrastructure? \\\n",
    " Provide a response in fewer than 1500 words using markdown.\"\n",
    "\n",
    "# Great answer. Slightly better than ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cbddfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query14 = \"Describe hydrogen's main physical characteristics such as flammability range, energy density, ignition energy, etc. \\\n",
    "Include the top 10 most cited physical characteristics and output in markdwon table.\"\n",
    "\n",
    "# Wow! Great answer. Same as ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d69335ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query15 = \"How does the cost of producing hydrogen from electrolysis compare with SMR w/CCS? \\\n",
    "Are there any particular regions in the US where electrolytic hydrogen is more cost effective? What makes that so? \\\n",
    "Provide an answer in bulleted list form in markdown. \"\n",
    "\n",
    "# Not a great answer. I feel prompt may be too generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c203c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "query16 = \"How should I think about deploying cost-effective electrolytic hydrogen? What are the major considerations? \\\n",
    "Provide an answer in bulleted list form in markdown. \"\n",
    "\n",
    "# Good answer. Same as ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1919d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "query17 = \"What are some ways to invest in the hydrogen market? Briefly describe each opportunity \\\n",
    "Provide an answer in bulleted list form in markdown in fewer than 1000 words. \"\n",
    "\n",
    "# Good answer. Nearly same as ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90b18ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query18 = \"Describe how CCS and CCUS work. What is the approximate cost of each technology? How do they pair with  \\\n",
    "hydrogen technologies? Provide an answer in bulleted list form in markdown in fewer than 1000 words. \"\n",
    "\n",
    "# Good answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ad041fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query19 = \"Describe the key differences between SMR and ATR. What are they? Which process is more efficient? \\\n",
    "Which technology is more cost effective? Provide an answer in bulleted list form in markdown in fewer than 1000 words. \"\n",
    "\n",
    "# Good answer. About same as ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "604e7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query20 = \"What carbon capture technologies should I consider for a SMR unit? How about for an ATR unit? \\\n",
    "What are the advantages and disadvantages for each carbon capture technology when paired with SMR or ATR? \\\n",
    "Provide an answer in bulleted list form in markdown in fewer than 2000 words. \"\n",
    "\n",
    "# Good answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d73c954",
   "metadata": {},
   "outputs": [],
   "source": [
    "query21 = \"How much does it cost to construct a natural gas pipeline? How about a hydrogen pipeline? \\\n",
    "What are the major differenences between the two? \\\n",
    "Provide an answer in bulleted list in markdown in fewer than 2000 words. \"\n",
    "\n",
    "# very mediocre answer. Need more depth here in this topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8c847d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query22 = \"How does liquefaction of hydrogen work? What is the cost of liquefaction at various scales? \\\n",
    "In what scenarios is gaseous delivery of hydrogen less economic the delivery of liquid hydrogen? \\\n",
    "Provide an answer in a bulleted list form in markdown in fewer than 1500 words. \"\n",
    "\n",
    "# Pretty good 1st order answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfb14eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query23 = \"Provide an overview of the various hydrogen carriers that could be used to transport hydrogen. \\\n",
    "How do the costs of each carrier compare? In what scenarios is one carrier favored over others? \\\n",
    "Provide an answer in a table form in markdown in fewer than 1500 words. Print out sources used to answer this. \"\n",
    "\n",
    "# Pretty good 1st order answer. About the same as ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cb016dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query24 = \"Provide an overview of how geologic hydrogen is produced. What are the processes? Where can it be found? \\\n",
    "Provide an answer in a table form in markdown in fewer than 1500 words. Print out sources used to answer. \"\n",
    "\n",
    "# Pretty good 1st order answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "346126c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query25 = \"Provide an in-depth review of how natural hydrogen occurs. What are the different processes? Where can it be found? \\\n",
    "Provide an answer in a table form in markdown in fewer than 3000 words. Print out sources used. \"\n",
    "\n",
    "# Not a great answer. Why is this? ChatGPT's answer is far worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b91a33e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to test AI doesn't hallucinate\n",
    "\n",
    "query_Hallucinate = \"What are the CO2 and particulate emissions of PEM electrolysis?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4faf4dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.908013582229614\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "- Grid-LTE: The levelized cost of production for Grid-LTE hydrogen production method is within the range of $2/kg H2. \n",
       "- PV-LTE: The levelized cost of production for PV-LTE hydrogen production method is within the range of $2/kg H2. \n",
       "- PV-MSALT-HTSE: The levelized cost of production for PV-MSALT-HTSE hydrogen production method is within the range of $2/kg H2. \n",
       "- Natural gas steam methane reforming (SMR): The levelized cost of production for SMR hydrogen production method is not specified in the given context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "response = index.query(query9, llm=llm)\n",
    "#response = qa_stuff.run(query)\n",
    "\n",
    "run_time = time.time()-start_time\n",
    "print(run_time)\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d7658d",
   "metadata": {},
   "source": [
    "### Section to test out returning citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "514ca65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d8fadbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(llm=llm, \n",
    "                                chain_type=\"stuff\",\n",
    "                                retriever=index.vectorstore.as_retriever(),\n",
    "                                return_source_documents=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d67aecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Provide an overview of the various hydrogen carriers that could be used to transport hydrogen. How do the costs of each carrier compare? In what scenarios is one carrier favored over others? Provide an answer in a table form in markdown in fewer than 1500 words. Print out sources used to answer this. ',\n",
       " 'answer': '| Hydrogen Carrier | Cost Comparison | Favored Scenarios |\\n|------------------|----------------|------------------|\\n| Liquid Hydrogen  | High           | Short-distance transport, small-scale applications |\\n| Ammonia          | Moderate       | Long-distance transport, maritime applications |\\n| LOHC             | Moderate       | Long-distance transport, large-scale applications |\\n| Compressed Hydrogen | High         | Local distribution, small-scale applications |\\n\\n',\n",
       " 'sources': '- \\\\Users\\\\markc\\\\Hydrogen\\\\FutureofHydrogen_IEA2019.pdf\\n- \\\\Users\\\\markc\\\\Hydrogen\\\\Zhang et al. - 2023 - Hydrogen liquefaction and storage Recent progress.pdf\\n- \\\\Users\\\\markc\\\\Hydrogen\\\\GlobalHydrogenReview2022_IEA.pdf'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_with_sources(query23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373528bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

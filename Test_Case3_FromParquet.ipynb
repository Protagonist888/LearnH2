{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20cc6a13",
   "metadata": {},
   "source": [
    "# LangChain: Evaluation¶\n",
    "### Outline:\n",
    "* Example generation\n",
    "* Manual evaluation (and debuging)\n",
    "* LLM-assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12b2ded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key:········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "import openai\n",
    "import time\n",
    "import markdown\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pickle\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358f8c3",
   "metadata": {},
   "source": [
    "# Create our QandA application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a4beefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "#PDF directory loader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769cc14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.11733150482178\n"
     ]
    }
   ],
   "source": [
    "# file = 'GlobalPowerPlantDB_USonly.csv'\n",
    "start_time = time.time()\n",
    "\n",
    "pdf_folder_path = \"/Users/markc/Hydrogen/\"\n",
    "loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
    "data = loader.load_and_split()\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "run_time = end_time-start_time\n",
    "print(run_time)\n",
    "\n",
    "# For 3900 pages...\n",
    "#loader.load() takes 137 sec\n",
    "#loader.load_and_split() takes 129 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73c0ee9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='California Air Resources Board  \\n1001 I Street \\nP.O. Box 2815 Sacramento, CA 95812 (916) 323-2514  \\narb.ca.govSustainable Transportation and \\nCommunities Division\\narb.ca.gov/our-work/programs/  \\nhydrogen-fueling-infrastructure\\ncleancars@arb.ca.gov', metadata={'source': '\\\\Users\\\\markc\\\\Hydrogen\\\\AB-8-Report-2022_CARB.pdf', 'page': 101})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(data))\n",
    "data[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1b7dde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8384"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.astype(str)\n",
    "df.rename(columns={0: 'Content', 1: 'Metadata'},inplace=True)\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88caff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to string so to_parquet will work\n",
    "df[df.columns[0]]=df[df.columns[0]].astype(str)\n",
    "df[df.columns[1]]=df[df.columns[1]].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d1601a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbfd9abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficient vectorstor method?\n",
    "# Setting vector indices for data\n",
    "start_time = time.time()\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])\n",
    "\n",
    "end_time = time.time()\n",
    "run_time = end_time-start_time\n",
    "print(run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d00bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why does chain_type not accept map_reduce?\n",
    "llm = ChatOpenAI(temperature = 0.0)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=index.vectorstore.as_retriever(), \n",
    "    verbose=True,\n",
    "    chain_type_kwargs = {\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f22e2",
   "metadata": {},
   "source": [
    "# Coming up with test datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6230250a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='20\\nAnnual Evaluation of Fuel Cell Electric Vehicle Deployment and Hydrogen Fuel Station Network DevelopmenttaBle 2: S tatiOn  netwOrk  and regiStered  FCev S witH reSpeCt  tO CluSter  deFintiOnS\\nClusterNumber \\nof Planned \\nStations in \\nClusterPlanned \\nCapacity in \\nCluster  \\n(kg/day)Percent of \\nPlanned \\nStationsPercent of \\nPlanned \\nCapacityPercent \\nof FCEV \\nRegistrations  \\nin Cluster\\nExpanded Network 68 56,754 62% 64% 60%\\nSouth San Francisco/ \\nBay Area14 10,299 13% 12% 11%\\nCoastal/South Orange County12 12,850 11% 15% 17%\\nTorrance 6 2,066 5% 2% 5%\\nBerkeley 6 4,903 5% 6% 2%\\nWest Los Angeles/ Santa Monica4 1,396 4% 2% 5%\\nAnalysis of Future On-The-Road FCEVs\\nProjections of future on-the-road FCEVs incorporate both the DMV registration data and auto \\nmanufacturer responses to the annual survey issued by CARB. CARB staff adjust submitted survey responses in three ways. First, CARB staff translate the responses provided in terms of model year into calendar year. As in all prior Annual Evaluations , one-third of the vehicles in a given model year \\nare assumed to be sold in the prior calendar year while the remaining two-thirds are assumed to be sold in the calendar year that matches the model year. This is applied to responses for all future model years but is not applied to responses for the remainder of the current model year.\\nNext, all statewide sales projections for each model year are distributed across all California \\ncounties. As in the 2021 Annual Evaluation , the proportion of FCEVs distributed to each county in \\neach year was determined by the proportion of projected fueling capacity in that county in the same year. This assumption was made because the capacity of the stations currently under development and planned for future development is quite large compared to historical network capacity and will likely drive the location of FCEV sales in the near future. Although the same method was used, the data in Table 3 are slightly different from similar data in the previous Annual Evaluation  because of \\nchanges to plans for future hydrogen fueling station development. \\nFinally, all FCEVs included in projections are assumed to be subject to an average attrition rate. \\nThis attrition adjustment represents the typical annual rate at which vehicles may be removed from the on-the-road fleet due to a number of issues, such as vehicle crashes and owners moving their vehicles out of state. This analysis utilizes the same method as CARB’s EMissions FACtor (EMFAC) model, which assumes vehicle attrition follows a power law curve with a vehicle half-life of 15 years. For example, under this model, a fleet of 100 initial vehicles will slowly be reduced each year for 15 years until there are 50 vehicles left in the fleet. The fleet would continue to slowly reduce in number over the next 15 years until 25 remain, and so on.  ', metadata={'source': '\\\\Users\\\\markc\\\\Hydrogen\\\\AB-8-Report-2022_CARB.pdf', 'page': 41})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38eecccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3906"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8661bc8a",
   "metadata": {},
   "source": [
    "# LLM-Generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ec7977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four boxes below generate Q&A pair to evaluate model\n",
    "from langchain.evaluation.qa import QAGenerateChain\n",
    "\n",
    "# Pass in OpenIA language model to interact with chain\n",
    "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37eb538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get back dictionary of question/answer pairs to evaluate\n",
    "#\n",
    "new_examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t} for t in data[:10]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3416dfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Since the publication of the 2021 Annual Evaluation, there have been a total of 8 new Open-Retail hydrogen fueling stations added to California's network, 6 of which opened in 2022.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See example\n",
    "new_examples[9]\n",
    "\n",
    "examples = []\n",
    "examples += new_examples\n",
    "\n",
    "qa.run(examples[9][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69b17e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b51a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Since the 2021 Annual Evaluation was published, a total of 8 new Open-Retail hydrogen fueling stations have been added to California's network, 6 of which opened in 2022.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "289ecafa",
   "metadata": {},
   "source": [
    "# Manual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40993c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "638d5879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Where was the source of the document located?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain > 3:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Where was the source of the document located?\",\n",
      "  \"context\": \"by-product sources.<<<<>>>>>information. Web posting. Summaries. \\nVerDate Sep 11 2014 12:25 Dec 28, 2021 Jkt 029139 PO 00058 Frm 00314 Fmt 6580 Sfmt 6581 E:\\\\PUBLAW\\\\PUBL058.117 PUBL058whamilton on LAPJF8D0R2PROD with PUBLAW<<<<>>>>>note. Records. Estimate. \\nVerDate Sep 11 2014 12:25 Dec 28, 2021 Jkt 029139 PO 00058 Frm 00345 Fmt 6580 Sfmt 6581 E:\\\\PUBLAW\\\\PUBL058.117 PUBL058whamilton on LAPJF8D0R2PROD with PUBLAW<<<<>>>>>1992 -UC-38; Pacific Northwest Laborator y: Richland, W A; 1976 .\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain > 3:chain:LLMChain > 4:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Use the following pieces of context to answer the users question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\nby-product sources.<<<<>>>>>information. Web posting. Summaries. \\nVerDate Sep 11 2014 12:25 Dec 28, 2021 Jkt 029139 PO 00058 Frm 00314 Fmt 6580 Sfmt 6581 E:\\\\PUBLAW\\\\PUBL058.117 PUBL058whamilton on LAPJF8D0R2PROD with PUBLAW<<<<>>>>>note. Records. Estimate. \\nVerDate Sep 11 2014 12:25 Dec 28, 2021 Jkt 029139 PO 00058 Frm 00345 Fmt 6580 Sfmt 6581 E:\\\\PUBLAW\\\\PUBL058.117 PUBL058whamilton on LAPJF8D0R2PROD with PUBLAW<<<<>>>>>1992 -UC-38; Pacific Northwest Laborator y: Richland, W A; 1976 .\\nHuman: Where was the source of the document located?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain > 3:chain:LLMChain > 4:llm:ChatOpenAI] [2.33s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The source of the document is not specified.\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"The source of the document is not specified.\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 260,\n",
      "      \"completion_tokens\": 9,\n",
      "      \"total_tokens\": 269\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain > 3:chain:LLMChain] [2.33s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"The source of the document is not specified.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 2:chain:StuffDocumentsChain] [2.33s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"The source of the document is not specified.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA] [2.96s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"The source of the document is not specified.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The source of the document is not specified.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(examples[4][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f86eb6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24c92c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "predictions = qa.apply(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e67f1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QAEvalChain evaluates question answer pairs\n",
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5176ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create above chain with language model. LLM will help do evaluation\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "062691fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get back graded outputs\n",
    "graded_outputs = eval_chain.evaluate(examples, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74e0bee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Question: What is the title of the report and what legislation is it pursuant to?\n",
      "Real Answer: The title of the report is \"2022 Annual Evaluation of Fuel Cell Electric Vehicle Deployment and Hydrogen Fuel Station Network Development\" and it is pursuant to Assembly Bill 8, also known as Perea, Chapter 401, Statutes of 2013.\n",
      "Predicted Answer: The context does not provide a clear answer to this question. However, it mentions several reports that the Secretary and Chiefs are required to submit to Congress, including a report with recommendations to Congress relating to the Program, a report describing methods, and additional reports for fiscal years 2022 and 2023. The legislation that these reports are pursuant to is also not specified in the context.\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "Example 1:\n",
      "Question: Who reviewed and approved the report for publication?\n",
      "Real Answer: The staff of the California Air Resources Board (CARB) reviewed and approved the report for publication.\n",
      "Predicted Answer: The report was reviewed by a panel of expert peer reviewers, including Professor Jack Brouwer, Professor Michael Kuby, Dr. Marc Melaina, Professor Joan Ogden, and Michael Penev, MBA, as well as several other reviewers listed in the context. However, it is not specified who approved the report for publication.\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "Example 2:\n",
      "Question: What is CARB's mission statement?\n",
      "Real Answer: CARB's mission is to promote and protect public health, welfare, and ecological resources through effective reduction of air pollutants while recognizing and considering effects on the economy.\n",
      "Predicted Answer: CARB's mission is to promote and protect public health, welfare, and ecological resources through effective reduction of air pollutants while recognizing and considering effects on the economy. CARB is the lead agency for climate change programs and oversees all air pollution control efforts in California to attain and maintain health-based air quality standards.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 3:\n",
      "Question: What is the purpose of the document mentioned in the metadata?\n",
      "Real Answer: The purpose of the document mentioned in the metadata is to provide information and analysis on the progress, provisions, and developments related to hydrogen fueling infrastructure in California.\n",
      "Predicted Answer: I'm sorry, but I cannot determine the document you are referring to as there is no mention of a specific document in the metadata provided. The metadata only includes snippets of text from different sections of different documents, making it difficult to determine the purpose of any specific document. Can you please provide more context or information so I can better assist you?\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 4:\n",
      "Question: Where was the source of the document located?\n",
      "Real Answer: The source of the document was located in the file path '\\\\Users\\\\markc\\\\Hydrogen\\\\AB-8-Report-2022_CARB.pdf'.\n",
      "Predicted Answer: The source of the document is not specified.\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "Example 5:\n",
      "Question: What does the acronym \"LCFS\" stand for?\n",
      "Real Answer: \"LCFS\" stands for \"Low Carbon Fuel Standard\".\n",
      "Predicted Answer: The acronym \"LCFS\" stands for \"Low Carbon Fuel Standard\".\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 6:\n",
      "Question: What is the source of the document and on which page is the content located?\n",
      "Real Answer: The source of the document is '\\\\Users\\\\markc\\\\Hydrogen\\\\AB-8-Report-2022_CARB.pdf' and the content is located on page 6.\n",
      "Predicted Answer: The source of the document is not specified and there is no content located on the page as it is intentionally left blank.\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "Example 7:\n",
      "Question: What is the goal of the Advanced Clean Cars II (ACC II) regulation proposed by the California Air Resources Board (CARB)?\n",
      "Real Answer: The goal of the Advanced Clean Cars II (ACC II) regulation proposed by the California Air Resources Board (CARB) is to achieve 100 percent zero-emission vehicle (ZEV) sales of new light-duty vehicles in California by 2035, as outlined in Governor Newsom’s Executive Order (EO) N-79-20.\n",
      "Predicted Answer: The goal of the Advanced Clean Cars II (ACC II) regulation proposed by the California Air Resources Board (CARB) is to achieve 100 percent zero-emission vehicle (ZEV) sales of new light-duty vehicles in California by 2035, as outlined by Governor Newsom's Executive Order (EO) N-79-20. This regulation aims to enable a transition to zero-emission transportation across all transportation sectors in California, including light-duty, medium-duty, heavy-duty, on-road, and off-road vehicles.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 8:\n",
      "Question: What is the purpose of California's Assembly Bill 8?\n",
      "Real Answer: California's Assembly Bill 8 (AB 8) provides the Energy Commission with up to $20 million annually through the end of 2023 to co-fund the development of hydrogen fueling stations in California. The goal is to address the hurdle of fueling infrastructure and ensure that FCEV use expands and becomes a viable ZEV option for an increasing number of Californians in the future. AB 8 requires that reports provide analysis of current and projected future FCEV deployment and hydrogen fueling station development and identify needs for further hydrogen station network development.\n",
      "Predicted Answer: The purpose of California's Assembly Bill 8 is to provide a financial resource to several programs through a fee applied to vehicle and vessel registrations, and to support the development and deployment of advanced transportation and fuel technologies, including supporting infrastructure for both hydrogen-fueled fuel cell electric vehicles (FCEVs) and electrically charged battery electric vehicles. The program was extended in 2013 with new provisions to co-fund the development of public hydrogen fueling stations.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 9:\n",
      "Question: How many new hydrogen fueling stations achieved Open-Retail status in California since the publication of the 2021 Annual Evaluation?\n",
      "Real Answer: Eight new hydrogen fueling stations achieved Open-Retail status in California since the publication of the 2021 Annual Evaluation.\n",
      "Predicted Answer: Since the publication of the 2021 Annual Evaluation, there have been a total of 8 new Open-Retail hydrogen fueling stations added to California's network, 6 of which opened in 2022.\n",
      "Predicted Grade: CORRECT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All below are output by the language mdoel\n",
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    print(\"Predicted Grade: \" + graded_outputs[i]['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0544ae3",
   "metadata": {},
   "source": [
    "## Key Questions/Concerns for Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "175e4298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What to do if predicted answers incorrect?\n",
    "# QAEvalChain spit out the same question multiple times\n",
    "# Try to access the UI that tracks what is going on \n",
    "#  under the hood (from langchain plus)\n",
    "# --generate flywheel of datapoints to learn from!!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dbfce8",
   "metadata": {},
   "source": [
    "### Try to query this new vectorstor database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5680fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What system design results in the lowest hydrogen breakeven cost? \\\n",
    "What is that cost in USD/kg? Is this with or without subsidies? Use markdown to describe.\"\n",
    "\n",
    "# Decent answer. High level, but limited by propmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "860a705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"What are the major challenges to deploying hydrogen and how can they become overcome?. \\\n",
    "Use bulleted markdown list to describe.\"\n",
    "\n",
    "# Decent answer. Relatively high level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f797b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"I wish to deploy hydrogen production in California. What technology should I use, where shoult it be placed,  \\\n",
    "what commercial models are suggested, and what federal or state incentives are applicable? Use markdown to describe.\"\n",
    "\n",
    "# Not a good answer. Very generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f568fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "query4 = \"What federal incentives exist for hydrogen production? \\\n",
    "Use markdown to describe.\"\n",
    "\n",
    "# Not specific enough answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b561445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query5 = \"What are ideal conditions for hydrogen in use as long duration storage? \\\n",
    "Use markdown to describe in fewer than 800 words in bulleted list and list hydrogen's top competitors.\"\n",
    "\n",
    "# Good answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "83e6eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query6 = \"You are an investor. What are ideal conditions and locations for hydrogen for use as long duration storage? \\\n",
    "Use markdown to describe in fewer than 800 words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "763e34d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query7 = \"Please describe how a PEM electrolyzer, alkaline electrolyzer, and solid oxide electrolyzer work. What are advantages and disadvantages for each? \\\n",
    "What is the average levelized cost of hydrogen production (in USD/kg) for each? Use markdown to describe in fewer than 1000 words.\"\n",
    "\n",
    "# Good answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f463bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to gauge breadth and depth of model's knowledge\n",
    "\n",
    "query8 = \"Please tell me the most cost-effective, scalable ways to decarbonize with hydrogen and \\\n",
    "the applications which hydrogen is most competitive in  decarbonizing. Do this in markdown in a bulleted list.\"\n",
    "\n",
    "# Decent answer. Lacks a bit of detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "87d4f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query9 = \"Please list the highest TRL hydrogen production methods and the range of their levelized cost of production in USD/kg. \\\n",
    "Do this in markdown in a bulleted list.\"\n",
    "\n",
    "#Good response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c21ab7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "query10 = \"What clean energy technologies are most competitive with hydrogen? \\\n",
    "What technologies are complementary to hydrogen? Display results in markdown in a table.\"\n",
    "\n",
    "#Poor response - probably due to knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b82d98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query11 = \"What are the main hydrogen provisions in the Clean Hydrogen Act? \\\n",
    "Create a bulleted list with short description. Display results in markdown in a table.\"\n",
    "\n",
    "#Poor response - probably due to knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4faf4dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.915264129638672\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "| Most Competitive with Hydrogen | Complementary to Hydrogen |\n",
       "|--------------------------------|---------------------------|\n",
       "| Solutions that directly use electricity | Diverse and complementary energy networks |\n",
       "|                                   | Flexible complement to other low-carbon energy technologies such as batteries and renewables |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "response = index.query(query10, llm=llm)\n",
    "#response = qa_stuff.run(query)\n",
    "\n",
    "run_time = time.time()-start_time\n",
    "print(run_time)\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79203b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "According to the given context, the integration with electricity markets and cheap renewable power sources could help achieve low breakeven costs for electrolytic hydrogen. The lowest hydrogen breakeven cost could be achieved today via direct wholesale market participation, which is around $3/kg. However, direct wholesale access is currently prohibited in CAISO under state law, but it is permissible in other organized wholesale markets. The profitability of hydrogen production also depends on electrolyzer siting. The context does not mention whether this cost includes subsidies or not."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f8fd8d",
   "metadata": {},
   "source": [
    "####  Key Question/Concerns for Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2551381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting unclear answers when combining all four reports\n",
    "# Does not seem to be correctly parsing through the data\n",
    "# Can it not read tables?\n",
    "# Why can't it generate more accurate answers?\n",
    "\n",
    "# QAGenerateChain.from_llm -> generates same questions. How to get higher fidelity questions?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
